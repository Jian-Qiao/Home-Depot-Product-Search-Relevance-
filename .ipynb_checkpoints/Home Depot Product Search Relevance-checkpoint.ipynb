{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pattern.en import singularize\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import Data\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "attributes=pd.read_csv('attributes.csv')\n",
    "description=pd.read_csv('product_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "description.index=description['product_uid']\n",
    "description=description.drop('product_uid',axis=1)\n",
    "#Remove Nan\n",
    "attributes=attributes.dropna(how='all')\n",
    "attributes.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Get a stats of attributes names\n",
    "all_names=attributes.groupby('name').count().sort_values('index',ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "attributes.product_uid.unique().__len__()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#Attributes with al least 5% occurance\n",
    "all_names.drop(all_names[all_names.value<4313].index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "attributes_2=attributes.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "def add_string(df):\n",
    "    return reduce((lambda x, y: str(x)+' '+str(y)),df.tolist())\n",
    "Color_Finish=attributes_2.loc[map(lambda x:re.search('(olor)|(inish)',x)!=None,attributes_2['name'])].groupby('product_uid').agg({'value':[add_string]})\n",
    "Color_Finish.columns=['Color_Finish']\n",
    "Bullets=attributes_2.loc[map(lambda x:re.search('(Bullet)',x)!=None,attributes_2['name'])].groupby('product_uid').agg({'value':[add_string]})\n",
    "Bullets.columns=['Bullets']\n",
    "Materials=attributes_2.loc[map(lambda x:re.search('(M|m)aterial',x)!=None,attributes_2['name'])].groupby('product_uid').agg({'value':[add_string]})\n",
    "Materials.columns=['Materials']\n",
    "Types=attributes_2.loc[map(lambda x:re.search('Product Type',x)!=None,attributes_2['name'])].groupby('product_uid').agg({'value':[add_string]})\n",
    "Types.columns=['Types']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attr_1=pd.merge(pd.merge(pd.merge(Color_Finish,Bullets,left_index=True,right_index=True),Materials,left_index=True,right_index=True),Types,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "Attr_2=pd.merge(Attr_1,test.groupby('product_uid').agg({'product_title':'first'}),left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attr_2.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attr_1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attr_2.columns=['Color_Finish','Bullets','Materials','Types','Title']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attr_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')\n",
    "def cleaning_text(sentence):\n",
    "    if isinstance(sentence,basestring):\n",
    "        sentence = unicode(sentence,'utf-8', errors='replace')\n",
    "        sentence=sentence.lower()\n",
    "        sentence=re.sub('[^\\w\\s]',' ', sentence) #removes punctuations\n",
    "        sentence=re.sub('_', ' ', sentence) #removes punctuations\n",
    "        sentence=re.sub('\\d+',' ', sentence) #removes digits\n",
    "        cleaned=' '.join([w for w in sentence.split() if not w in stop]) \n",
    "        cleaned=' '.join([singularize(w) for w in sentence.split() ]) #remove pural\n",
    "        #removes english stopwords\n",
    "        cleaned=' '.join([w for w , pos in pos_tag(cleaned.split()) if (pos == 'NN' or pos=='JJ' or pos=='JJR' or pos=='JJS' )])\n",
    "        #selecting only nouns and adjectives\n",
    "\n",
    "        cleaned=' '.join([w for w in cleaned.split() if not len(w)<=2 ]) \n",
    "        #removes single lettered words and digits\n",
    "        cleaned=cleaned.strip()\n",
    "        return cleaned\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bullets_cleaned=Bullets['Bullets'].apply(lambda x: cleaning_text(x))\n",
    "Description_cleaned=description['product_description'].apply(lambda x: cleaning_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Description_cleaned.index=description.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Search_Term=pd.Series(train.search_term.append(test.search_term))\n",
    "Search_Term=Search_Term.apply(lambda x: cleaning_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer1 = CountVectorizer(max_df=0.95, min_df=2, max_features=200,\n",
    "                                stop_words='english')\n",
    "tf_vectorizer2 = CountVectorizer(max_df=0.95, min_df=2, max_features=100,\n",
    "                                stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf1 = tf_vectorizer1.fit_transform(np.array(Description_cleaned.replace(np.nan, '')))\n",
    "tf2 = tf_vectorizer2.fit_transform(np.array(Search_Term.replace(np.nan,'')))\n",
    "TF = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf_idf_Bullets = TF.fit_transform(tf1)\n",
    "tf_idf_Description=TF.fit_transform(tf1)\n",
    "tf_idf_Search_Term= TF.fit_transform(tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Trans_Bullets=pd.DataFrame(tf_idf_Bullets.toarray())\n",
    "#Trans_Bullets.index=Bullets.index\n",
    "Trans_Description=pd.DataFrame(tf_idf_Description.toarray())\n",
    "Trans_Description.index=description.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trans_Search_Term=pd.DataFrame(tf_idf_Search_Term.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0.200641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0    1    2    3    4    5    6         7    8         9    \\\n",
       "product_uid                                                                    \n",
       "100001       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "100002       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.140434  0.0  0.000000   \n",
       "100003       0.200641  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "100004       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "100005       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.190483   \n",
       "\n",
       "               ...     190  191       192  193  194  195       196  197  198  \\\n",
       "product_uid    ...                                                             \n",
       "100001         ...     0.0  0.0  0.198178  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
       "100002         ...     0.0  0.0  0.000000  0.0  0.0  0.0  0.404098  0.0  0.0   \n",
       "100003         ...     0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
       "100004         ...     0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
       "100005         ...     0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "                  199  \n",
       "product_uid            \n",
       "100001       0.000000  \n",
       "100002       0.172098  \n",
       "100003       0.000000  \n",
       "100004       0.000000  \n",
       "100005       0.098232  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trans_Bullets.head()\n",
    "Trans_Description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...    90   91   92   93  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    94   95   96   97   98   99  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_Search_Term.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.index=train['product_uid']\n",
    "Trans_Search_Term=Trans_Search_Term[0:len(train)]\n",
    "Trans_Search_Term.index=train['product_uid']\n",
    "Trans_Search_Term['relevance']=train['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_vec=pd.merge(Trans_Bullets,Trans_Search_Term,left_index=True,right_index=True)\n",
    "train_vec=pd.merge(Trans_Description,Trans_Search_Term,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Relevance=train_vec['relevance']\n",
    "train_vec=train_vec.drop(['relevance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param={}\n",
    "param['eta']=0.02\n",
    "param['max_depth']=6\n",
    "param['silent']=1\n",
    "param['eval_metric']='mlogloss'\n",
    "param['min_child_weight']=3\n",
    "param['subsample']=0.7\n",
    "param['colsample_bytree']=0.7\n",
    "num_rounds=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 484.22 seconds\n"
     ]
    }
   ],
   "source": [
    "start_ = time.time()\n",
    "\n",
    "#x_train = np.array(train_vec.iloc[0:50000])\n",
    "#y_train = np.array(Relevance.iloc[0:50000])\n",
    "\n",
    "#x_validation = np.array(train_vec.iloc[50000:])\n",
    "#y_validation = np.array(Relevance.iloc[50000:])\n",
    "x_train, x_validation, y_train, y_validation=model_selection.train_test_split(train_vec,Relevance,test_size=0.3)\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_train, label= y_train)\n",
    "\n",
    "clf = xgb.train(param, xgtrain, num_rounds)\n",
    "\n",
    "xgvalidation = xgb.DMatrix(x_validation)\n",
    "y_prob = clf.predict(xgvalidation)\n",
    "\n",
    "print 'Time elapsed: %.2f seconds' % (time.time() - start_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is  0.523370471427\n"
     ]
    }
   ],
   "source": [
    "print 'MSE is ',np.std(y_prob-y_validation)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_set=pd.merge(Attr_2,train,left_index=True,right_on='product_uid')\n",
    "\n",
    "train_match=pd.DataFrame(columns=train_set.columns)\n",
    "\n",
    "train_match=train_match[['Color_Finish','Bullets','Materials','Types','Title']]\n",
    "\n",
    "def word_syn(search_term,match_term):\n",
    "#    if cla=='N':\n",
    "#        pos=['NN','NNS','NNP']\n",
    "#    elif cla=='A':\n",
    "#        pos=['JJ','JJR','JJS']\n",
    "#    else:\n",
    "#        pos=['NN','NNS','NNP','JJ','JJR','JJS']\n",
    "    simi=[]\n",
    "    for word1, pos1 in pos_tag(search_term.split()):\n",
    "        simi_word=[]\n",
    "        for word2, pos2 in pos_tag(match_term.split()):\n",
    "            if(pos2 in pos1):\n",
    "                single_simi=0\n",
    "                for s1 in wn.synsets(word1):\n",
    "                    for s2 in wn.synsets(word2):\n",
    "                        if s1.path_similarity(s2)>single_simi:\n",
    "                            single_simi=s1.path_similarity(s2)\n",
    "                simi_word.append(single_simi)\n",
    "        if(len(simi_word)>0):\n",
    "            simi.append(max(simi_word))\n",
    "        else:\n",
    "            simi.append(0)\n",
    "            \n",
    "    return np.mean(simi)\n",
    "\n",
    "def match_word(a,b):\n",
    "    if isinstance(a,basestring)==False | isinstance(b,basestring)==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return word_syn(a,b)\n",
    "\n",
    "for i in range(3589,len(train_set)):\n",
    "    train_match=train_match.append(train_set[['Color_Finish','Bullets','Materials','Types','Title']].iloc[i].apply(\n",
    "            lambda x: match_word(cleaning_text(train_set.search_term.iloc[i]),cleaning_text(x))))\n",
    "\n",
    "pd.DataFrame.to_csv(train_match,'train_match.csv')\n",
    "\n",
    "train_match=pd.read_csv('train_match.csv')\n",
    "\n",
    "train_match.index=train_match.iloc[:,0]\n",
    "\n",
    "train_match=train_match.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "train_match['relevance']=train_set['relevance']\n",
    "\n",
    "train_match=train_match.dropna(axis=0,how='any')\n",
    "train_match.shape\n",
    "\n",
    "X_train=train_match[0:7000].drop(['relevance'],axis=1)\n",
    "X_test=train_match[7000:].drop(['relevance'],axis=1)\n",
    "Y_train=train_match[0:7000].relevance\n",
    "Y_test=train_match[7000:].relevance\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test=model_selection.train_test_split(train_match.drop(['relevance'],axis=1),train_match['relevance'],test_size=0.5)\n",
    "\n",
    "svc_1=SVC()\n",
    "\n",
    "Y_train=Y_train.astype('string')\n",
    "\n",
    "svc_1.fit(X_train,Y_train)\n",
    "\n",
    "svc_1_test=svc_1.predict(X_test)\n",
    "\n",
    "svc_1_test\n",
    "\n",
    "svc_1.score(X_test,Y_test.astype('string'))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf=MLPClassifier(hidden_layer_sizes=(5,1),solver='lbfgs',alpha=0.5)\n",
    "\n",
    "clf.fit(X_train,Y_train.astype('string'))\n",
    "\n",
    "prediction=clf.predict(X_test)\n",
    "\n",
    "def test_accu(a,b):\n",
    "    if len(a)==len(b):\n",
    "        R=0.\n",
    "        for i in range(len(a)):\n",
    "            if a.iloc[i].astype('string')==b[i]:\n",
    "                R+=1\n",
    "        return R/len(a)\n",
    "    else:\n",
    "        print 'Not same length'\n",
    "\n",
    "test_accu(Y_test,prediction)\n",
    "\n",
    "Y_test.head()\n",
    "\n",
    "R=1\n",
    "R+=1\n",
    "print R\n",
    "\n",
    "train_match.head()\n",
    "\n",
    "a=10\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
