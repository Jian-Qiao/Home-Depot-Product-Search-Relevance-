{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.2.2 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Data\n",
    "train_data=pd.read_csv('train.csv')\n",
    "test_data=pd.read_csv('test.csv')\n",
    "#attributes=pd.read_csv('attributes.csv')\n",
    "description=pd.read_csv('product_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=train_data.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = unicode(sentence,'utf-8', errors='replace')\n",
    "    cleaned=' '.join([stemmer.stem(w) for w in sentence.split()])\n",
    "    cleaned=' '.join([w for w in cleaned.split() if w not in stop])\n",
    "    cleaned=re.sub('\\W',' ',cleaned)\n",
    "    cleaned=' '.join([w for w in cleaned.split() if w != 'x' and w!= 'in'])\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.search_term=train_data.search_term.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "description.product_description=description.product_description.apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.product_title=train_data.product_title.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>simpson strong ti 12 gaug angl</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>simpson strong ti 12 gaug angl</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>behr premium textur deckov 1 gal sc 141 tugboa...</td>\n",
       "      <td>deck</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100005</td>\n",
       "      <td>delta vero 1 handl shower onli faucet trim kit...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>delta vero 1 handl shower onli faucet trim kit...</td>\n",
       "      <td>shower onli faucet</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                      product_title  \\\n",
       "0       100001                     simpson strong ti 12 gaug angl   \n",
       "1       100001                     simpson strong ti 12 gaug angl   \n",
       "2       100002  behr premium textur deckov 1 gal sc 141 tugboa...   \n",
       "3       100005  delta vero 1 handl shower onli faucet trim kit...   \n",
       "4       100005  delta vero 1 handl shower onli faucet trim kit...   \n",
       "\n",
       "          search_term  relevance  \n",
       "0        angl bracket       3.00  \n",
       "1           l bracket       2.50  \n",
       "2                deck       3.00  \n",
       "3    rain shower head       2.33  \n",
       "4  shower onli faucet       2.67  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>simpson strong ti 12 gaug angl</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>3.00</td>\n",
       "      <td>onli angl make joint stronger also provid cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>simpson strong ti 12 gaug angl</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "      <td>onli angl make joint stronger also provid cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>behr premium textur deckov 1 gal sc 141 tugboa...</td>\n",
       "      <td>deck</td>\n",
       "      <td>3.00</td>\n",
       "      <td>behr premium textur deckov innov solid color c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100005</td>\n",
       "      <td>delta vero 1 handl shower onli faucet trim kit...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>updat bathroom delta vero single handl shower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>delta vero 1 handl shower onli faucet trim kit...</td>\n",
       "      <td>shower onli faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>updat bathroom delta vero single handl shower ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                      product_title  \\\n",
       "0       100001                     simpson strong ti 12 gaug angl   \n",
       "1       100001                     simpson strong ti 12 gaug angl   \n",
       "2       100002  behr premium textur deckov 1 gal sc 141 tugboa...   \n",
       "3       100005  delta vero 1 handl shower onli faucet trim kit...   \n",
       "4       100005  delta vero 1 handl shower onli faucet trim kit...   \n",
       "\n",
       "          search_term  relevance  \\\n",
       "0        angl bracket       3.00   \n",
       "1           l bracket       2.50   \n",
       "2                deck       3.00   \n",
       "3    rain shower head       2.33   \n",
       "4  shower onli faucet       2.67   \n",
       "\n",
       "                                 product_description  \n",
       "0  onli angl make joint stronger also provid cons...  \n",
       "1  onli angl make joint stronger also provid cons...  \n",
       "2  behr premium textur deckov innov solid color c...  \n",
       "3  updat bathroom delta vero single handl shower ...  \n",
       "4  updat bathroom delta vero single handl shower ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec=pd.merge(train_data,description,left_on='product_uid',right_on='product_uid')\n",
    "\n",
    "train_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spell correcting\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter('\\n'.join(s for s in train_vec.product_description.as_matrix().flatten()).split())\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vec.search_term=train_vec.search_term.apply(lambda x: ' '.join([correction(w) for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vec.to_csv('myplayingwithdataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_train=pd.DataFrame(np.zeros([len(train_vec),5]),columns=['Title_1','Desc_1','Title_2','Desc_2','Len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink(k):\n",
    "    return 1-1/np.exp(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_docu_in_search(sentence, docu):\n",
    "    wf=[]\n",
    "    for word in sentence.split():\n",
    "        wf.append((np.array(docu.split())==[word]).sum()/1.0/len(docu.split()))\n",
    "    return np.array(wf).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_search_in_docu(sentence, docu):\n",
    "    wf=[]\n",
    "    for word in sentence.split():\n",
    "        wf.append((np.array(docu.split())==[word]).sum())\n",
    "    return shrink(np.array(wf)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(train_vec)):\n",
    "    to_train['Title'][i]=my_tf_df(train_vec['search_term'][i],train_vec['product_title'][i])\n",
    "    to_train['Desc'][i]=my_tf_df(train_vec['search_term'][i],train_vec['product_description'][i])\n",
    "    to_train['Len'][i]=len(train_vec['search_term'][i].split())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_vec)):\n",
    "    to_train['Title_1'][i]=my_docu_in_search(train_vec['search_term'][i],train_vec['product_title'][i])\n",
    "    to_train['Desc_1'][i]=my_docu_in_search(train_vec['search_term'][i],train_vec['product_description'][i])\n",
    "    to_train['Title_2'][i]=my_search_in_docu(train_vec['search_term'][i],train_vec['product_title'][i])\n",
    "    to_train['Desc_2'][i]=my_search_in_docu(train_vec['search_term'][i],train_vec['product_description'][i])\n",
    "    to_train['Len'][i]=len(train_vec['search_term'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_train['uid']=train_vec['product_uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param={}\n",
    "param['eta']=0.01\n",
    "param['max_depth']=6\n",
    "param['silent']=1\n",
    "param['eval_metric']='rmse'\n",
    "param['min_child_weight']=3\n",
    "param['subsample']=0.7\n",
    "param['colsample_bytree']=0.7\n",
    "num_rounds=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ = time.time()\n",
    "\n",
    "#x_train = np.array(train_vec.iloc[0:50000])\n",
    "#y_train = np.array(Relevance.iloc[0:50000])\n",
    "\n",
    "#x_validation = np.array(train_vec.iloc[50000:])\n",
    "#y_validation = np.array(Relevance.iloc[50000:])\n",
    "x_train, x_validation, y_train, y_validation=model_selection.train_test_split(to_train,train_vec['relevance'],test_size=0.3)\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_train, label= y_train)\n",
    "xgvalidation=xgb.DMatrix(x_validation,label=y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.93746\teval-rmse:1.93792\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.839695\teval-rmse:0.840028\n",
      "[200]\ttrain-rmse:0.540075\teval-rmse:0.542403\n",
      "[300]\ttrain-rmse:0.483827\teval-rmse:0.488405\n",
      "[400]\ttrain-rmse:0.474139\teval-rmse:0.480557\n",
      "[500]\ttrain-rmse:0.471425\teval-rmse:0.479447\n",
      "[600]\ttrain-rmse:0.469888\teval-rmse:0.479246\n",
      "[700]\ttrain-rmse:0.468619\teval-rmse:0.479234\n",
      "Stopping. Best iteration:\n",
      "[633]\ttrain-rmse:0.469459\teval-rmse:0.479226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.train(param, xgtrain, num_rounds,evals=[ (xgtrain,'train'),(xgvalidation,'eval')],\n",
    "                early_stopping_rounds=100, verbose_eval =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
